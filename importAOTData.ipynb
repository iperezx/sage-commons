{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,json,os,time\n",
    "import pandas as pd\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "apiKey=os.getenv('CKANAPIKEY')\n",
    "if apiKey is None:\n",
    "    raise EnvironmentError(\"Failed because {} is not set.\".format('CKANAPIKEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataResource(apiEndpoint,headers,payload):\n",
    "    response = requests.request(\"POST\", apiEndpoint, headers=headers, json = payload)\n",
    "    return response\n",
    "    \n",
    "def getMetadata(filePath):\n",
    "    mk = open(filePath).read()\n",
    "    html = markdown.markdown(mk)\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    \n",
    "    # get h3 headers\n",
    "    metadataTypes = soup.find_all('h3')\n",
    "    metadataTypesList = ['Files']\n",
    "\n",
    "    for tag in metadataTypes:\n",
    "        metadataTypesList.append(tag.text)\n",
    "    \n",
    "    #get contents under h3 \n",
    "    metadata = soup.find_all('li')\n",
    "    filesMetadata = []\n",
    "    \n",
    "    for i,tag in enumerate(metadata):\n",
    "        check = tag.find('code')\n",
    "        if check is not None:\n",
    "            source = tag.find('code').text\n",
    "            content = tag.text\n",
    "            contentsDict = {source:content.replace(source+ ' - ','')}\n",
    "            filesMetadata.append(contentsDict)\n",
    "\n",
    "    #combine all\n",
    "    numFiles=[4,7,9,3,8,6]\n",
    "    fullMetadata={file: None for file in metadataTypesList if file != 'Useful Links'}\n",
    "    start = 0\n",
    "    end = numFiles[0]\n",
    "    tempData = filesMetadata[start:end]\n",
    "    fullMetadata['Files'] = {k: v for d in tempData for k, v in d.items()}\n",
    "    \n",
    "    fullMetadata['Files']['data.csv'] = fullMetadata['Files']['data.csv.gz']\n",
    "    del fullMetadata['Files']['data.csv.gz']\n",
    "\n",
    "    start = numFiles[0]\n",
    "    end = sum(numFiles[0:2])\n",
    "    tempData = filesMetadata[start:end]\n",
    "    fullMetadata['Sensor Data'] = {k: v for d in tempData for k, v in d.items()}\n",
    "\n",
    "    start = sum(numFiles[0:2])\n",
    "    end = sum(numFiles[0:3])\n",
    "    tempData = filesMetadata[start:end]\n",
    "    fullMetadata['Node Metadata'] = {k: v for d in tempData for k, v in d.items()}\n",
    "\n",
    "    #skip three\n",
    "    start = sum(numFiles[0:4])\n",
    "    end = sum(numFiles[0:5])\n",
    "    tempData = filesMetadata[start:end]\n",
    "    fullMetadata['Sensor Metadata'] ={k: v for d in tempData for k, v in d.items()}\n",
    "\n",
    "    start = sum(numFiles[0:5])\n",
    "    end = sum(numFiles[0:6])\n",
    "    tempData = filesMetadata[start:end]\n",
    "    fullMetadata['Provenance Metadata'] = {k: v for d in tempData for k, v in d.items()}\n",
    "    \n",
    "    return fullMetadata\n",
    "    \n",
    "def getDataForCKAN(filePath,orient='records'):\n",
    "    dataDF = pd.read_csv(dataPath)\n",
    "    dataDict = dataDF.to_dict(orient=orient)\n",
    "    return dataDict\n",
    "\n",
    "def getFieldsTemplate():\n",
    "    template = {\n",
    "                \"id\": None,\n",
    "                \"info\": \n",
    "                {\n",
    "                    \"label\": None,\n",
    "                    \"notes\": None\n",
    "                }\n",
    "            }\n",
    "    return template\n",
    "\n",
    "def getFieldsForCKAN(metadata):\n",
    "    fieldsList=[]\n",
    "    for key,val in metadata.items():\n",
    "        template = getFieldsTemplate()\n",
    "        template['id'] = key\n",
    "        template['info']['label'] = key\n",
    "        template['info']['notes'] = val\n",
    "        fieldsList.append(template)\n",
    "    return fieldsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDir = '/Users/iperezx/Documents/sage-commons/sage-commons-aot/'\n",
    "sageCommonsURL='http://hotshot.sdsc.edu:5000'\n",
    "headers = {'Authorization': apiKey}\n",
    "orgName= 'array-of-things'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get directories of datasets\n",
    "directories = [f.path for f in os.scandir(mainDir) if f.is_dir() and f.name.startswith('chicago')]\n",
    "print(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeNames = ['daily','weekly','monthly']\n",
    "dataDir = directories[1]\n",
    "dataFiles = [f for f in sorted(os.listdir(dataDir)) if os.path.isfile(os.path.join(dataDir, f))] \n",
    "timeData = {key: None for key in timeNames}\n",
    "for val in timeNames:\n",
    "    timeData[val] = {key: None for key in dataFiles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFiles = [f for f in sorted(os.listdir(dataDir)) if os.path.isfile(os.path.join(dataDir, f))]\n",
    "metaDataFilePath= os.path.join(dataDir,dataFiles[0])\n",
    "metadata = getMetadata(metaDataFilePath)\n",
    "lookupFile={'data.csv':'Sensor Data',\n",
    "            'sensors.csv':'Sensor Metadata',\n",
    "            'provenance.csv':'Provenance Metadata',\n",
    "            'nodes.csv':'Node Metadata'}\n",
    "\n",
    "# print(json.dumps(metadata, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import chicago daily data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiAction='/api/3/action/package_create'\n",
    "url = sageCommonsURL+apiAction\n",
    "\n",
    "dataDir = directories[1]\n",
    "title = dataDir.replace(mainDir,'')\n",
    "\n",
    "timeType = 'daily'\n",
    "name = 'chicago-' + timeType\n",
    "\n",
    "tags = [{'name':'csv'},{'name':'waggle'},{'name':'sensors'},{'name': timeType}]\n",
    "\n",
    "payload = {'owner_org': orgName,\n",
    "           'title': title,\n",
    "           'name' : name,\n",
    "           'notes': 'Description of dataset',\n",
    "           'tags' : tags\n",
    "          }\n",
    "\n",
    "response = createDataResource(url,headers,payload)\n",
    "jsonResponseDS = response.json()\n",
    "print(response)\n",
    "print(json.dumps(jsonResponseDS, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiAction='/api/3/action/datastore_create'\n",
    "packageID = jsonResponseDS['result']['id']\n",
    "url = sageCommonsURL+apiAction\n",
    "\n",
    "dataFiles = [f for f in sorted(os.listdir(dataDir)) if os.path.isfile(os.path.join(dataDir, f)) and f!='README.md' and f!='offsets.csv']\n",
    "\n",
    "for dataFile in dataFiles:\n",
    "    dataPath= os.path.join(dataDir,dataFile)\n",
    "    name = os.path.splitext(dataFile)[0]\n",
    "    records = getDataForCKAN(dataPath)\n",
    "    \n",
    "    resource = {'package_id': packageID,\n",
    "                'name' : name,\n",
    "                'description': metadata['Files'][dataFile]\n",
    "               }\n",
    "    \n",
    "    fields = getFieldsForCKAN(metadata[lookupFile[dataFile]])\n",
    "    \n",
    "    \n",
    "    payload = {'resource': resource,\n",
    "               'fields': fields,\n",
    "               'records': records\n",
    "              }\n",
    "\n",
    "    \n",
    "    start = time.time() # start timing\n",
    "    response = requests.request(\"POST\", url, headers=headers, json = payload)\n",
    "    end = time.time()\n",
    "    timeData[timeType][dataFile] = abs(end-start)\n",
    "#     jsonResponse = response.json()\n",
    "#     print(response)\n",
    "#     print(response.text)\n",
    "#     print(json.dumps(jsonResponse, indent=4, sort_keys=True))\n",
    "    \n",
    "    print('Elapsed time: ' + str(timeData[timeType][dataFile]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import chicago weekly data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiAction='/api/3/action/package_create'\n",
    "url = sageCommonsURL+apiAction\n",
    "\n",
    "dataDir = directories[2]\n",
    "title = dataDir.replace(mainDir,'')\n",
    "\n",
    "timeType = 'weekly'\n",
    "name = 'chicago-' + timeType\n",
    "\n",
    "tags = [{'name':'csv'},{'name':'waggle'},{'name':'sensors'},{'name': timeType}]\n",
    "\n",
    "payload = {'owner_org': orgName,\n",
    "           'title': title,\n",
    "           'name' : name,\n",
    "           'notes': 'Description of dataset',\n",
    "           'tags' : tags\n",
    "          }\n",
    "response = requests.request(\"POST\", url, headers=headers, json = payload)\n",
    "jsonResponseDS = response.json()\n",
    "print(response)\n",
    "print(json.dumps(jsonResponseDS, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiAction='/api/3/action/datastore_create'\n",
    "packageID = jsonResponseDS['result']['id']\n",
    "url = sageCommonsURL+apiAction\n",
    "\n",
    "dataFiles = [f for f in sorted(os.listdir(dataDir)) if os.path.isfile(os.path.join(dataDir, f)) and f!='README.md' and f!='offsets.csv']\n",
    "\n",
    "for dataFile in dataFiles:\n",
    "    dataPath= os.path.join(dataDir,dataFile)\n",
    "    name = os.path.splitext(dataFile)[0]\n",
    "    records = getDataForCKAN(dataPath)\n",
    "    \n",
    "    resource = {'package_id': packageID,\n",
    "                'name' : name,\n",
    "                'description': metadata['Files'][dataFile]\n",
    "               }\n",
    "    \n",
    "    fields = getFieldsForCKAN(metadata[lookupFile[dataFile]])\n",
    "    \n",
    "    \n",
    "    payload = {'resource': resource,\n",
    "               'fields': fields,\n",
    "               'records': records\n",
    "              }\n",
    "\n",
    "    \n",
    "    start = time.time() # start timing\n",
    "    response = requests.request(\"POST\", url, headers=headers, json = payload)\n",
    "    end = time.time()\n",
    "    timeData[timeType][dataFile] = abs(end-start)\n",
    "#     jsonResponse = response.json()\n",
    "#     print(response)\n",
    "#     print(response.text)\n",
    "#     print(json.dumps(jsonResponse, indent=4, sort_keys=True))\n",
    "    \n",
    "    print('Elapsed time: ' + str(timeData[timeType][dataFile]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(timeData, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import chicago monthly data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiAction='/api/3/action/package_create'\n",
    "url = sageCommonsURL+apiAction\n",
    "\n",
    "dataDir = directories[0]\n",
    "title = dataDir.replace(mainDir,'')\n",
    "\n",
    "timeType = 'monthly'\n",
    "name = 'chicago-' + timeType\n",
    "\n",
    "tags = [{'name':'csv'},{'name':'waggle'},{'name':'sensors'},{'name': timeType}]\n",
    "\n",
    "payload = {'owner_org': orgName,\n",
    "           'title': title,\n",
    "           'name' : name,\n",
    "           'notes': 'Description of dataset',\n",
    "           'tags' : tags\n",
    "          }\n",
    "response = requests.request(\"POST\", url, headers=headers, json = payload)\n",
    "jsonResponseDS = response.json()\n",
    "print(response)\n",
    "print(json.dumps(jsonResponseDS, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiAction='/api/3/action/datastore_create'\n",
    "packageID = jsonResponseDS['result']['id']\n",
    "url = sageCommonsURL+apiAction\n",
    "\n",
    "dataFiles = [f for f in sorted(os.listdir(dataDir)) if os.path.isfile(os.path.join(dataDir, f)) and f!='README.md' and f!='offsets.csv']\n",
    "\n",
    "for dataFile in dataFiles:\n",
    "    dataPath= os.path.join(dataDir,dataFile)\n",
    "    name = os.path.splitext(dataFile)[0]\n",
    "    records = getDataForCKAN(dataPath)\n",
    "    \n",
    "    resource = {'package_id': packageID,\n",
    "                'name' : name,\n",
    "                'description': metadata['Files'][dataFile]\n",
    "               }\n",
    "    \n",
    "    fields = getFieldsForCKAN(metadata[lookupFile[dataFile]])\n",
    "    \n",
    "    \n",
    "    payload = {'resource': resource,\n",
    "               'fields': fields,\n",
    "               'records': records\n",
    "              }\n",
    "\n",
    "    \n",
    "    start = time.time() # start timing\n",
    "    response = requests.request(\"POST\", url, headers=headers, json = payload)\n",
    "    end = time.time()\n",
    "    timeData[timeType][dataFile] = abs(end-start)\n",
    "#     jsonResponse = response.json()\n",
    "#     print(response)\n",
    "#     print(response.text)\n",
    "#     print(json.dumps(jsonResponse, indent=4, sort_keys=True))\n",
    "    \n",
    "    print('Elapsed time: ' + str(timeData[timeType][dataFile]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
